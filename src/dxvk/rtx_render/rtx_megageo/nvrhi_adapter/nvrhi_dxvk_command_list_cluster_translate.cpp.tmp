  void NvrhiDxvkCommandList::translateClusterOperation(
    const nvrhi::rt::cluster::OperationDesc& nvrhiDesc,
    VkClusterAccelerationStructureCommandsInfoNV& vkCmds)
  {
    // NOTE: The Vulkan cluster AS API has changed significantly.
    // The actual implementation needs adaptation based on RTX Remix's usage patterns.
    // For now, this is a stub that sets up the basic structure.

    // TODO: Implement proper translation once we understand how RTX Remix uses cluster AS
    // The new API uses:
    // - opType (BUILD_TRIANGLE_CLUSTER, BUILD_CLUSTERS_BOTTOM_LEVEL, etc.)
    // - opMode (COMPUTE_SIZES, EXPLICIT_DESTINATIONS, IMPLICIT_DESTINATIONS)
    // - opInput union with pTriangleClusters, pClustersBottomLevel, or pMoveObjects
    // - Strided arrays for srcInfosArray, dstAddressesArray, dstSizesArray

    memset(&vkCmds, 0, sizeof(vkCmds));
    vkCmds.sType = VK_STRUCTURE_TYPE_CLUSTER_ACCELERATION_STRUCTURE_COMMANDS_INFO_NV;

    // Basic operation mode translation
    VkClusterAccelerationStructureInputInfoNV& input = vkCmds.input;
    input.sType = VK_STRUCTURE_TYPE_CLUSTER_ACCELERATION_STRUCTURE_INPUT_INFO_NV;
    input.maxAccelerationStructureCount = nvrhiDesc.maxArgCount;

    // Map operation type
    switch (nvrhiDesc.params.type) {
      case nvrhi::rt::cluster::OperationType::ClasBuildTemplates:
        input.opType = VK_CLUSTER_ACCELERATION_STRUCTURE_OP_TYPE_BUILD_TRIANGLE_CLUSTER_TEMPLATE_NV;
        break;
      case nvrhi::rt::cluster::OperationType::ClasInstantiateTemplates:
        input.opType = VK_CLUSTER_ACCELERATION_STRUCTURE_OP_TYPE_INSTANTIATE_TRIANGLE_CLUSTER_NV;
        break;
      case nvrhi::rt::cluster::OperationType::BlasBuild:
        input.opType = VK_CLUSTER_ACCELERATION_STRUCTURE_OP_TYPE_BUILD_CLUSTERS_BOTTOM_LEVEL_NV;
        break;
    }

    // Map operation mode
    switch (nvrhiDesc.params.mode) {
      case nvrhi::rt::cluster::OperationMode::GetSizes:
        input.opMode = VK_CLUSTER_ACCELERATION_STRUCTURE_OP_MODE_COMPUTE_SIZES_NV;
        break;
      case nvrhi::rt::cluster::OperationMode::ExplicitDestinations:
        input.opMode = VK_CLUSTER_ACCELERATION_STRUCTURE_OP_MODE_EXPLICIT_DESTINATIONS_NV;
        break;
      case nvrhi::rt::cluster::OperationMode::ImplicitDestinations:
        input.opMode = VK_CLUSTER_ACCELERATION_STRUCTURE_OP_MODE_IMPLICIT_DESTINATIONS_NV;
        break;
    }

    // Set up srcInfosArray (indirect args buffer)
    if (nvrhiDesc.inIndirectArgsBuffer) {
      NvrhiDxvkBuffer* argsBuffer = static_cast<NvrhiDxvkBuffer*>(nvrhiDesc.inIndirectArgsBuffer);
      vkCmds.srcInfosArray.deviceAddress = argsBuffer->getGpuVirtualAddress() + nvrhiDesc.inIndirectArgsOffsetInBytes;
      vkCmds.srcInfosArray.stride = argsBuffer->getDesc().structStride;
      vkCmds.srcInfosArray.size = argsBuffer->getDesc().byteSize - nvrhiDesc.inIndirectArgsOffsetInBytes;
    }

    // Set up output buffers if provided
    if (nvrhiDesc.outResultBuffer) {
      NvrhiDxvkBuffer* resultBuffer = static_cast<NvrhiDxvkBuffer*>(nvrhiDesc.outResultBuffer);
      vkCmds.dstAddressesArray.deviceAddress = resultBuffer->getGpuVirtualAddress();
      vkCmds.dstAddressesArray.stride = sizeof(VkDeviceAddress);
      vkCmds.dstAddressesArray.size = nvrhiDesc.maxArgCount * sizeof(VkDeviceAddress);
    }

    if (nvrhiDesc.outScratchBuffer) {
      NvrhiDxvkBuffer* scratchBuffer = static_cast<NvrhiDxvkBuffer*>(nvrhiDesc.outScratchBuffer);
      vkCmds.scratchData = scratchBuffer->getGpuVirtualAddress();
    }
  }
